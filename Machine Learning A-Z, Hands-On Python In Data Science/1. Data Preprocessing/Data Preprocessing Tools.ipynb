{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d7799a",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc91e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f25c1",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e1fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data.csv\")\n",
    "dataset\n",
    "#creating two new entities 1. Matrix of features and 2. dependent variable vector\n",
    " # x - matrix of features\n",
    "# y - dependent variables\n",
    "\n",
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69078a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix of features => \n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "\n",
      "dependent variables => \n",
      " ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"matrix of features => \\n\",x)\n",
    "print(\"\\ndependent variables => \\n\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fd182",
   "metadata": {},
   "source": [
    "### Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2114d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods of dealing with missing data\n",
    "#1. if the missing data is <=1% the better to delete those rows\n",
    "#2. filling the missing data with the average value of the whole column\n",
    "#3. or either by filling with the mode value of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b0a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:, 1:3])\n",
    "x[:, 1:3] = imputer.transform(x[:, 1:3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54007db5",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616a8e7",
   "metadata": {},
   "source": [
    "#### 1. Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb83c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "# With one-hot, we convert each categorical value into a new categorical column and assign a binary \n",
    "# value of 1 or 0 to those columns. Each integer value is represented as a binary vector\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# transformers=[(kind_of_transformation i.e encoding, type_of_encoding i.e one-hot-encoding, index's of column)]\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder=\"passthrough\")\n",
    "x = np.array(ct.fit_transform(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0ee8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f342c1f",
   "metadata": {},
   "source": [
    "##### 2.encoding the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736ac34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405eed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2da74",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5883fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1 0 0 1 1 0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9bcd38",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a8e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "\n",
    "x_test[:, 3:] = sc.transform(x_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83cfbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, -0.19159184384578545, -1.0781259408412425],\n",
       "       [0.0, 1.0, 0.0, -0.014117293757057777, -0.07013167641635372],\n",
       "       [1.0, 0.0, 0.0, 0.566708506533324, 0.633562432710455],\n",
       "       [0.0, 0.0, 1.0, -0.30453019390224867, -0.30786617274297867],\n",
       "       [0.0, 0.0, 1.0, -1.9018011447007988, -1.420463615551582],\n",
       "       [1.0, 0.0, 0.0, 1.1475343068237058, 1.232653363453549],\n",
       "       [0.0, 1.0, 0.0, 1.4379472069688968, 1.5749910381638885],\n",
       "       [1.0, 0.0, 0.0, -0.7401495441200351, -0.5646194287757332]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe4ae92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, -1.4661817944830124, -0.9069571034860727],\n",
       "       [1.0, 0.0, 0.0, -0.44973664397484414, 0.2056403393225306]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
